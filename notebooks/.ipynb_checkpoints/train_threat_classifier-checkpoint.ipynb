{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66b0fbd8-e584-452e-af9e-2fdbcfa45f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start \n",
      "\n",
      "ðŸ“Š Model Evaluation Results:\n",
      "\n",
      "--- Logistic Regression ---\n",
      "Accuracy: 0.9500\n",
      "Precision: 0.9025\n",
      "Recall: 0.9500\n",
      "F1 Score: 0.9256\n",
      "\n",
      "--- Random Forest ---\n",
      "Accuracy: 0.9500\n",
      "Precision: 0.9025\n",
      "Recall: 0.9500\n",
      "F1 Score: 0.9256\n",
      "\n",
      "--- Decision Tree ---\n",
      "Accuracy: 0.7500\n",
      "Precision: 0.8906\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.8143\n",
      "\n",
      "--- KNN ---\n",
      "Accuracy: 0.9500\n",
      "Precision: 0.9025\n",
      "Recall: 0.9500\n",
      "F1 Score: 0.9256\n",
      "\n",
      "--- SVM ---\n",
      "Accuracy: 0.9500\n",
      "Precision: 0.9025\n",
      "Recall: 0.9500\n",
      "F1 Score: 0.9256\n",
      "\n",
      "--- Gradient Boosting ---\n",
      "Accuracy: 0.8500\n",
      "Precision: 0.8972\n",
      "Recall: 0.8500\n",
      "F1 Score: 0.8730\n",
      "\n",
      "--- Naive Bayes ---\n",
      "Accuracy: 0.8500\n",
      "Precision: 0.8972\n",
      "Recall: 0.8500\n",
      "F1 Score: 0.8730\n",
      "\n",
      "\n",
      "âœ… Best model: Logistic Regression with F1 score: 0.9256\n",
      "ðŸ”’ Model and preprocessing objects saved for future use.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"start \")\n",
    "# === 1. Load the dataset ===\n",
    "df = pd.read_csv(\"logs_2.csv\")\n",
    "\n",
    "# === 2. Drop rows with missing values (optional) ===\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# === 3. Encode categorical features ===\n",
    "cat_features = ['source_ip', 'destination_ip', 'protocol', 'user_agent', 'location', 'port']\n",
    "encoders = {}\n",
    "\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "# === 4. Convert numeric fields ===\n",
    "numeric_cols = ['bytes_sent', 'bytes_received']\n",
    "df[numeric_cols] = df[numeric_cols].astype(float)\n",
    "\n",
    "# === 5. Encode target ===\n",
    "target_encoder = LabelEncoder()\n",
    "df['threat'] = target_encoder.fit_transform(df['threat'])\n",
    "\n",
    "# === 6. Feature / Label split ===\n",
    "X = df.drop(columns=['timestamp', 'threat'])\n",
    "y = df['threat']\n",
    "\n",
    "# === 7. Train/test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === 8. Feature scaling ===\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# === 9. Define models ===\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# === 10. Train, evaluate, select best ===\n",
    "best_model = None\n",
    "best_f1 = 0\n",
    "\n",
    "print(\"\\nðŸ“Š Model Evaluation Results:\\n\")\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted')\n",
    "    rec = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "# === 11. Save the best model ===\n",
    "joblib.dump(best_model, \"best_model.joblib\")\n",
    "joblib.dump(scaler, \"scaler.joblib\")\n",
    "joblib.dump(encoders, \"encoders.joblib\")\n",
    "joblib.dump(target_encoder, \"target_encoder.joblib\")\n",
    "\n",
    "print(f\"\\nâœ… Best model: {best_model_name} with F1 score: {best_f1:.4f}\")\n",
    "print(\"ðŸ”’ Model and preprocessing objects saved for future use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32958793-4a26-42db-a95d-923bd223ecf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    source_ip  destination_ip  protocol  port  user_agent  location  \\\n",
      "0          45               3         0     3           0         1   \n",
      "1          92              82         2     5           3         9   \n",
      "2          49              39         1     2           2         3   \n",
      "3          31              97         1     3           1         6   \n",
      "4          91              17         1     4           3         5   \n",
      "5          19              50         1     2           0         6   \n",
      "6          87              14         1     4           3         2   \n",
      "7          66              48         1     5           4         7   \n",
      "8          59              71         2     2           2         0   \n",
      "9           1              86         1     4           1         8   \n",
      "10          2              95         2     5           4         3   \n",
      "11          6              74         1     6           2         0   \n",
      "12         88              75         2     1           1         1   \n",
      "13         67              91         1     2           1         5   \n",
      "14         48              69         0     4           4         6   \n",
      "15         13              56         0     6           4         1   \n",
      "16         52              36         0     6           4         7   \n",
      "17         80               1         2     3           2         6   \n",
      "18         95              19         0     0           3         5   \n",
      "19         34              38         1     4           4         9   \n",
      "\n",
      "    bytes_sent  bytes_received predicted_threat  \n",
      "0       3402.0          4327.0             none  \n",
      "1       3793.0          3392.0             none  \n",
      "2       1574.0          2450.0             none  \n",
      "3        715.0          2203.0             none  \n",
      "4       3426.0          4051.0             none  \n",
      "5       4954.0          4392.0             none  \n",
      "6       3478.0          1395.0             none  \n",
      "7        580.0          2739.0             none  \n",
      "8       1440.0          2496.0             none  \n",
      "9       3561.0           765.0          malware  \n",
      "10      1207.0          3871.0             none  \n",
      "11       591.0           855.0             none  \n",
      "12      1640.0          4804.0             none  \n",
      "13      1813.0          2108.0             none  \n",
      "14      3528.0          4682.0             none  \n",
      "15      4463.0          4153.0             none  \n",
      "16      4825.0          1556.0             none  \n",
      "17      2370.0          4291.0             none  \n",
      "18      2078.0          3497.0             none  \n",
      "19      1426.0          1468.0             none  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "print(\"start \")\n",
    "# Load the pretrained components\n",
    "model = joblib.load(\"best_model.joblib\")\n",
    "scaler = joblib.load(\"scaler.joblib\")\n",
    "encoders = joblib.load(\"encoders.joblib\")\n",
    "target_encoder = joblib.load(\"target_encoder.joblib\")\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"logs_2.csv\")\n",
    "\n",
    "# Get the original feature order from the scaler\n",
    "feature_order = scaler.feature_names_in_  # This contains the original training feature order\n",
    "\n",
    "# Drop rows with missing values in the feature columns\n",
    "df.dropna(subset=feature_order, inplace=True)\n",
    "\n",
    "# Encode categorical features using saved LabelEncoders\n",
    "for col in [\"source_ip\", \"destination_ip\", \"protocol\", \"user_agent\", \"location\", \"port\"]:\n",
    "    le = encoders[col]\n",
    "    mapping = {cls: idx for idx, cls in enumerate(le.classes_)}\n",
    "    df[col] = df[col].map(mapping).fillna(-1).astype(int)  # unseen values mapped to -1\n",
    "\n",
    "# Convert numeric columns to float\n",
    "df[\"bytes_sent\"] = df[\"bytes_sent\"].astype(float)\n",
    "df[\"bytes_received\"] = df[\"bytes_received\"].astype(float)\n",
    "\n",
    "# Prepare feature matrix in correct order (using scaler's original order)\n",
    "X = df[feature_order]\n",
    "\n",
    "# Scale features\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Predict\n",
    "preds = model.predict(X_scaled)\n",
    "df[\"predicted_threat\"] = target_encoder.inverse_transform(preds)\n",
    "\n",
    "# Show results\n",
    "print(df[list(feature_order) + [\"predicted_threat\"]].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1bcc95-5677-4a1d-ac2b-300ad030d324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
